
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":" I am currently employed as a Quantitative Researcher at Brevan Howard. Prior to joining Brevan Howard, I successfully completed my PhD in Statistics at the London School of Economics. During my doctoral journey, I was advised by Kostas Kalogeropoulos and Pauline Barrieu.\nMy PhD studies primarily focused on the application of Sequential Bayesian Learning for State Space Models. This involved developing methodologies to estimate model parameters in both batch and time series settings, with a particular emphasis on latent variable models.\nIn addition to my academic pursuits, I have actively contributed to the open source community. You can find some of my notable contributions here. Furthermore, if you would like to review my detailed qualifications and professional experiences, you can download a copy of my CV here.\n","date":1675123200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675123200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently employed as a Quantitative Researcher at Brevan Howard. Prior to joining Brevan Howard, I successfully completed my PhD in Statistics at the London School of Economics. During my doctoral journey, I was advised by Kostas Kalogeropoulos and Pauline Barrieu.","tags":null,"title":"Patrick Aschermayr","type":"authors"},{"authors":[],"categories":null,"content":"","date":1679922000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679922000,"objectID":"2a373620b6d3be95e624008f1222c6e4","permalink":"https://paschermayr.github.io/talk/lse-2023-viva/","publishdate":"2023-03-27T13:00:00Z","relpermalink":"/talk/lse-2023-viva/","section":"talk","summary":"Sequential Bayesian Inference for State Space Models","tags":[],"title":"PhD VIVA","type":"talk"},{"authors":["Patrick Aschermayr","Alexandros Beskos","Konstantinos Kalogeropoulos","Aristidis Nikolopoulos"],"categories":null,"content":"","date":1675123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675123200,"objectID":"9c61046b5953607370c7e17eba76fa71","permalink":"https://paschermayr.github.io/publication/20230131_copulasv/","publishdate":"2023-01-31T00:00:00Z","relpermalink":"/publication/20230131_copulasv/","section":"publication","summary":"Stochastic Volatility (SV) models are a popular class of models to analyze the dependency structure between stocks and their volatility. In this paper, we develop a new class of SV models by incorporating carefully selected copula structures to reconstruct stylised empirical behaviours that cannot be captured by symmetric Gaussian innovations.","tags":["Copula","Stochastic Volatility","Markov Chain Monte Carlo","Sequential Monte Carlo","Model Selection"],"title":"A Class of Stochastic Volatility Models with Copula Dependencies","type":"publication"},{"authors":["Patrick Aschermayr","Konstantinos Kalogeropoulos","Nikolaos Demiris"],"categories":null,"content":"","date":1675036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675036800,"objectID":"102fa97b710646322e5da38153ecd0bc","permalink":"https://paschermayr.github.io/publication/20230130_covid19hsmm/","publishdate":"2023-01-30T00:00:00Z","relpermalink":"/publication/20230130_covid19hsmm/","section":"publication","summary":"In this paper, we propose an epidemic model with the transmission rate between susceptible and infected individuals, β, being time varying and piecewise constant. At any point in time, β is linked to a latent variable that follows a Hidden Semi-Markov Model (HSMM). This HSMM-driven epidemic Model (HSMM-EM) structures the data into multiple regimes, which greatly enhances decision-making capabilities, while the limited number of continuous model parameter guarantees straightforward model interpretation.","tags":["Epidemic Models","Markov Chain Monte Carlo","Sequential Monte Carlo","Particle Filter","Model Selection"],"title":"SIR-type State Space Models with Piecewise Constant Transmission Rates","type":"publication"},{"authors":["Patrick Aschermayr","Konstantinos Kalogeropoulos"],"categories":null,"content":"","date":1674950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674950400,"objectID":"ccf20234bf91b49dc1263a38e4afc827","permalink":"https://paschermayr.github.io/publication/20230129_sequentialhsmm/","publishdate":"2023-01-29T00:00:00Z","relpermalink":"/publication/20230129_sequentialhsmm/","section":"publication","summary":"In this paper, we explore the class of the Hidden Semi-Markov Model (HSMM), a flexible extension of the popular Hidden Markov Model (HMM) that allows the underlying stochastic process to be a semi-Markov chain. A major motivation of this paper is to provide methods to estimate HSMMs (1) in a computationally feasible time, (2) in an exact manner, i.e. only subject to Monte Carlo error, and (3) in a sequential setting.","tags":["Hidden Markov Model","Hidden Semi-Markov Model","Markov Chain Monte Carlo","Sequential Monte Carlo","Particle Filter","Model Selection"],"title":"Sequential Bayesian Learning for Hidden Semi-Markov Models","type":"publication"},{"authors":["Patrick Aschermayr"],"categories":null,"content":"","date":1671494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671494400,"objectID":"e1a204d98b5ed3fbc0c65781b5beb8c8","permalink":"https://paschermayr.github.io/publication/20221220_phdthesis/","publishdate":"2022-12-20T00:00:00Z","relpermalink":"/publication/20221220_phdthesis/","section":"publication","summary":"My doctoral research evolves around the topic of Sequential Bayesian Learning for State Space Models. More generally, I am working on estimating model parameters in a batch as well as in a times series setting, with a focus on latent variable models. This thesis includes projects with Hidden Semi-Markov Models, Copulae, and Epidemic Models that have latent factors attached.","tags":["Hidden Markov Model","Hidden Semi-Markov Model","Copula","Stochastic Volatility","Epidemic Models","Markov Chain Monte Carlo","Sequential Monte Carlo","Particle Filter","Model Selection"],"title":"Sequential Bayesian Learning for State Space Models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1656507600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656507600,"objectID":"a290d820275a41f3d56029b220dc263e","permalink":"https://paschermayr.github.io/talk/lse-2022-ims/","publishdate":"2022-06-29T13:00:00Z","relpermalink":"/talk/lse-2022-ims/","section":"talk","summary":"Sequential Bayesian Learning for Hidden Semi-Markov Models (HSMM)","tags":[],"title":"IMS 2022 Conference - Contributed Talk","type":"talk"},{"authors":null,"categories":null,"content":"Baytes.jl is a package to perform Bayesian inference. It consists of several sub-libraries, such as BaytesMCMC.jl, BaytesFilters.jl, BaytesPMCMC.jl and BaytesSMC.jl, and provides an interface to combine kernels from these packages. Check it out here.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"57f72897d061c9704843a745b2b113cb","permalink":"https://paschermayr.github.io/opensource/baytes/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/opensource/baytes/","section":"opensource","summary":"Framework for Sequential Bayesian Inference","tags":["Bayesian Statistics","Markov Chain Monte Carlo","Markov Chain Monte Carlo","Parameter Estimation"],"title":"Baytes.jl","type":"opensource"},{"authors":["Patrick Aschermayr"],"categories":["Academic","Teaching","Bayesian Statistics"],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"a8b2bfd6f17b24c3a48ae5af2351862f","permalink":"https://paschermayr.github.io/teaching/lse-2022-st308-bayesian-inference/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/teaching/lse-2022-st308-bayesian-inference/","section":"teaching","summary":"Graduate teaching assistant in my fourth year of PhD studies at the LSE.","tags":["Academic","Teaching","Bayesian Statistics"],"title":"LSE - ST308 - Bayesian Inference (2022)","type":"teaching"},{"authors":null,"categories":null,"content":"ModelWrappers.jl is a utility package that makes it easier to work with Model parameters stated as (nested) NamedTuples. It provides a framework to represent parameters as (nested) tuples or vectors. Parameters can be shown in constrained or unconstrained domain, and representations are fully compatible with multiple Automatic Differentiation frameworks. Check it out here.\n","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"f66c8ccc417892d404d1f90f6aa7d61b","permalink":"https://paschermayr.github.io/opensource/modelwrapppers/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/opensource/modelwrapppers/","section":"opensource","summary":"Framework to represent parameters as (nested) tuples or vectors","tags":["Model Parameter","Parameter Estimation"],"title":"ModelWrappers.jl","type":"opensource"},{"authors":[],"categories":null,"content":"","date":1619874000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619874000,"objectID":"a3f4c580312d836f35cadb711ab6d775","permalink":"https://paschermayr.github.io/talk/lse-2021-phd-research-update/","publishdate":"2021-05-01T13:00:00Z","relpermalink":"/talk/lse-2021-phd-research-update/","section":"talk","summary":"Sequential Bayesian Learning on State Space Models","tags":[],"title":"Research Update Presentation","type":"talk"},{"authors":["Patrick Aschermayr"],"categories":["Academic","Teaching","Bayesian Statistics"],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"fe2e1fd6daea02e5a624b77c792674b5","permalink":"https://paschermayr.github.io/teaching/lse-2021-st308-bayesian-inference/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/teaching/lse-2021-st308-bayesian-inference/","section":"teaching","summary":"Graduate teaching assistant in my third year of PhD studies at the LSE.","tags":["Academic","Teaching","Bayesian Statistics"],"title":"LSE - ST308 - Bayesian Inference (2021)","type":"teaching"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Particle MCMC for State Space Model Estimation\nBuilding our first PMCMC algorithm! This will be the final post of the series where everything will (hopefully) come together. In the first posts about HMMs and HSMMs, I explained the basics about said models. In the first blog post of my Inference in state space models series, I outlined a rough sketch on how to conduct parameter estimation for these models, and concluded that Bayesian methods are particularly suitable if we want to jointly sample the model parameter and the state sequence given the observed data. In the following post, I coded up a basic particle filter from scratch to sample the state sequence and, in my latest post, I implemented a framework to sample the corresponding model parameter. Please note that going forward you will need to import all Julia functions that we defined so far in order to make the code in this article work. If you do not want to copy paste code through all the articles, you can download the Julia scripts from my GitHub profile.\nExplaining the estimation problem Let us straight jump into the topic: the goal is to infer the posterior $P( s_{1:T}, \\theta \\mid e_{1:T})$. $\\theta$ is, in our case, all the observation and transition parameter. If we assume univariate Normal observation distributions, we need to estimate $\\mu$ and $\\sigma$ for each state. In addition, we need to estimate the transition matrix, which I will keep fixed for now. You can also estimate this matrix if you extend our code in the MCMC part of the series for vector valued distributions. As a quick recap, we will use the particle filter from this post to sample the state trajectory, and the Metropolis sampler from this post to propose new model parameter. With the information gathered from both steps, we will either accept or reject this pair.\nCoding the PMCMC framework Let us start by loading all necessary libraries and defining two helper functions that we need in the PMCMC framework: a function to transfer the current values in our parameter container into the corresponding model distributions as well as a function to show all current values in this parameter container.\n#Support function to transfer parameter into distributions function get_distribution(μᵥ::Vector{ParamInfo}, σᵥ::Vector{ParamInfo}) return [Normal(μᵥ[iter].value, σᵥ[iter].value) for iter in eachindex(μᵥ)] end get_distribution(param::HMMParameter) = get_distribution(param.μ, param.σ) #Support function to grab all parameter in HMMParameter container function get_parameter(parameter::HMMParameter) θ = Float64[] for field_name in fieldnames( typeof( parameter ) ) sub_field = getfield(parameter, field_name ) append!(θ, [sub_field[iter].value for iter in eachindex(sub_field) ] ) end return θ end get_parameter (generic function with 1 method) Neither of the two functions are needed to grasp the concept of PMCMC, but are useful for the sampling process. Next, let us sample the corresponding observed and latent data for some HMM. We will use these model parameter later on to compare the accuracy of our PMCMC algorithm:\n#Generate data T = 100 evidence_true = [Normal(2., 1.), Normal(-2.,1.)] transition_true = [ Categorical([0.85, 0.15]), Categorical([0.5, 0.5]) ] s, e = sampleHMM(evidence_true, transition_true, T) #Plot data plot( layout=(2,1), label=false, margin=-2Plots.px) plot!(e, ylabel=\u0026#34;observed data\u0026#34;, label=false, subplot=1, color=\u0026#34;gold4\u0026#34;) plot!(s, yticks = (1:2), ylabel=\u0026#34;latent state\u0026#34;, label=false, subplot=2, color=\u0026#34;black\u0026#34;) I explained this code already in an earlier post, so check this one out if there are any unclarities. I will now initialize the model parameter and the corresponding particle filter - note that there are many methods to do so, but for now we just initialize them manually, far enough away from the true parameter:\n#Generate Initial parameter estimates - for univariate normal observations μᵥ = [ParamInfo(3.0, Normal() ), ParamInfo(-3.0, Normal() )] #Initial value and Prior σᵥ = [ParamInfo(1.5, Gamma(2,2) ), ParamInfo(2.0, Gamma(2,2) )] #Initial value and Prior param_initial = HMMParameter(μᵥ, σᵥ) #Generate initial state trajectory evidence_current = get_distribution(param_initial) transition_current = deepcopy(transition_true) initial_current = Categorical( gth_solve( Matrix(get_transition_param(transition_current) ) ) ) pf = ParticleFilter(initial_current, transition_current, evidence_current) You can check out this post if the code above is still unclear to you. Now all that is left to do is implementing the PMCMC sampling routine. I did my best to comment and make the code as clear as possible by adding comments at almost each line - the steps itself do not differ much from a standard Metropolis algorithm, so this function should be relatively straightforward to understand. The Unicode support for Julia also helps a lot here, as I could use a subscript t for variables that are defined in the transformed parameter space. Some more comments to understand the code a bit …","date":1605312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605312000,"objectID":"9ae82dfbd107337fe26feca719e8c651","permalink":"https://paschermayr.github.io/post/statespacemodels-3-inference-on-state-space-models-part-4/","publishdate":"2020-11-14T00:00:00Z","relpermalink":"/post/statespacemodels-3-inference-on-state-space-models-part-4/","section":"post","summary":"Particle MCMC for State Space Model Estimation","tags":["State Space Models","Particle MCMC","Hidden Markov Model","Julia"],"title":"Bayesian Inference on State Space Models - Part 4","type":"post"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Almost done! In my previous blog posts here and here, we explored a general framework on how to conduct parameter estimation for state space models (SSM), and took a first step in implementing this machinery. In order to apply Particle MCMC (PMCMC), we have to\nFind a good proposal distribution $f(\\theta^{\\star} \\mid \\theta)$ for $ \\theta^{\\star}$. Find a good proposal distribution $P(s^\\star_{1:T} \\mid \\theta^{\\star}, e_{1:T})$ for $ S^{\\star}_{1:T}$. Find a sufficiently ‘good’ likelihood approximation $\\hat{\\mathcal{L}}$$_{\\theta}(e_{1:T})$ that we can plug into the acceptance rate. We have already tackled the latter two problems in the previous posts, so what about the first one?\nThe MCMC in PMCMC If we want to jointly sample the parameter vector $\\theta$, the first thing we need to do is to check the corresponding boundary conditions of our parameter. For instance, if we want to estimate parameter of univariate normal observations, the mean parameter is typically defined on the whole Reals, while the variance is constrained to be positive. There are several ways to proceed:\ni. We could, in principle, use some multivariate proposal distribution $f( . \\mid \\theta)$, and reject all proposals where one of the parameter falls outside of the corresponding boundaries. This is, as you already guessed, very wasteful.\nii. Alternatively, you could use a truncated multivariate proposal distribution. Note that this is NOT the same as (i.), as one needs to adjust the normalisation constants in the MH acceptance ratio, see this blog post for a more detailed explanation. This approach is intuitively more efficient than the first option, but highly model specific and sometimes difficult to track for errors.\niii. Another possibility is to first transform the corresponding parameter into an unconstrained space, perform the MCMC step in this unconstrained space, and then transform the proposed parameter back into the original space for the likelihood evaluation. In this case, we have to be careful when calculating the prior. As we are now working with the transformed parameter, we need to adjust the prior distribution with the Jacobian of the transform (keyword: push-forward measure). If you have trouble understanding that, I recommend this explanation before you proceed reading. This approach has a much higher initial workload, but to my mind is the most general and effective way to perform MCMC, and almost all libraries that you use work in this way under the hood. Consequently, we will focus on the third case.\nSo, how can we code this up? The most straightforward way to implement this approach is by using information from the corresponding prior: boundaries, length and dimension of each parameter can be inferred from here. I will use a new Julia package Bijectors.jl that makes the workflow significantly easier, but there are similar packages in other languages as well.\nCoding it all up In my last post, we implemented a particle filter for basic hidden Markov models, so let us continue to use this example. Hence, we are interested in the mean and variance parameter for each state, and the corresponding transition matrix of the latent Markov chain. For now, let us assume the transition matrix is known, so we can implement the MCMC machinery for scalar based parameter, and do not need to extend our functions for vector valued parameter. To my mind, this would put too much attention to the code rather than the actual topic. We start by creating a container that can hold one parameter and its corresponding priors.\nusing Distributions, Bijectors, Parameters import Base: count #A container with necessary information about θ mutable struct ParamInfo{T, D\u0026lt;:Union{Nothing, \u0026lt;:Distributions.Distribution} } value :: T #Can be Real, Integer, or a Arrays composed of it prior :: D #Corresponding prior of value, needs to fulfill boundary constraints! end ParamInfo(value::T) where {T} = ParamInfo(value, nothing) #Check the number of parameter in ParamInfo struct function count(paraminfo::ParamInfo) return length(paraminfo.value) end count (generic function with 17 methods) Note that I also defined a function that informs us about the parameter size inside this container. Next, we will make a summary container for all the different parameter that we will need during the tutorial - i.e., mean and variance parameter of a univariate Normal distribution for each state in the basic HMM case.\n#A summary container for all relevant parameter mutable struct HMMParameter μ :: Vector{ParamInfo} #Observation Distribution Mean σ :: Vector{ParamInfo} #Observation Distribution Variance end Further, we want to define some helper functions that enable us to transform and inverse transform the parameter in said container. Remember that our goal is to sample from some unconstrained space, and then inverse transform said parameter back to our constrained space. This will help us to accept more parameter proposals in the MCMC step. Note that I will use a …","date":1604016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604016000,"objectID":"5bba9f1275c458247441f6e255d3504a","permalink":"https://paschermayr.github.io/post/statespacemodels-3-inference-on-state-space-models-part-3/","publishdate":"2020-10-30T00:00:00Z","relpermalink":"/post/statespacemodels-3-inference-on-state-space-models-part-3/","section":"post","summary":"MCMC for State Space Model Estimation","tags":["State Space Models","Particle MCMC","Hidden Markov Model","Markov Chain Monte Carlo","Julia"],"title":"Bayesian Inference on State Space Models - Part 3","type":"post"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Welcome back! In my previous blog post, we explored a general framework to conduct parameter estimation on state space models (SSM). We call this framework Particle MCMC (PMCMC), and the three major steps to successfully apply this algorithm are as follows:\nFind a good proposal distribution $f(\\theta^{\\star} \\mid \\theta)$ for $ \\theta^{\\star}$. Find a good proposal distribution $P(s^\\star_{1:T} \\mid \\theta^{\\star}, e_{1:T})$ for $ S^{\\star}_{1:T}$. Find a sufficiently ‘good’ likelihood approximation $\\hat{\\mathcal{L}}$$_{\\theta}(e_{1:T})$ that we can plug into the acceptance rate. In this post, we will try to solve problems 2. and 3. simultaneously. Hence, we need to find a way to sample a state trajectory and get an approximation for the likelihood given the current parameter vector $\\theta$. In order to use all the code we use here, please load all the functions from my introductory HMM article, or just include the corresponding HMM Julia file from my GitHub account.\nFiltering the latent state trajectory In PMCMC, a particle filter (PF) is used to first sample a trajectory $s^{\\star}_{1:T}$ and then calculate an unbiased estimate of the corresponding likelihood. Note that unbiased does not mean our estimate is automatically ‘good’ enough, so there is quite a bit of ongoing research on how to keep the variance of particle filter likelihood estimates in check. For an in-depth explanation about PFs, I refer to (Doucet and Johansen, 2011), as explaining the whole machinery of it in detail is simply out of reach in a simple blog post.\nIn a nutshell, particle filters are usually used to solve filtering equations in the form of $$ \\begin{equation} \\begin{split} \\pi_t( x_{1:t} ) \u0026amp;= \\frac{ \\tau_t(x_{1:t}) }{ Z_t }. \\\\ \u0026amp;= \\frac{ w_{1:t} q_t(x_{1:t}) }{ Z_t }\\ \\end{split} \\end{equation} $$\nHere, the goal is to sequentially sample a sequence of random variables, $X_t, t \\in (1,…, T)$ that come from a sequence of target probabilities $\\pi_t( x_{1:t} )$ with the same computational complexity at each time step. The last part is crucial as we do not want to increase the computing time as more and more data comes in. You will notice I rewrote the equation by introducing $w_{1:t}=\\frac{ \\tau_t(x_{1:t}) }{ q_t(x_{1:t}) }$. Those familiar with importance sampling will likely understand why, but the reason we did so is because usually it is very difficult to sample from $\\tau_t(x_{1:t})$. We introduce an easier distribution $q_t(x_{1:t})$ and reweight this distribution via $w_{1:t}$. Consequently, we need to find a good proposal distribution $q_t(x_{1:t})$, such that the computational complexity will not increase over time. A convenient by-product is that we can approximate the normalizing constant $Z_t$ with these weights: $$ \\begin{equation} \\hat{Z_t} = \\frac{1}{t} \\sum_{i=1}^{K} \\frac{\\tau_t(x_{1:t})}{q_t(x_{1:t})} = \\frac{1}{t} \\sum_{i=1}^{K} w_t(x^i_{1:t}). \\end{equation} $$\nIn the basic HMM case, the joint distribution and the normalizing constant are of the form $\\tau_t(x_{1:t}) = \\prod_{k=1}^{t} f(s_k \\mid s_{k-1}) g(e_k \\mid s_k)$ and $Z = p(e_{1:t})$. Hence you can use the weights from above to approximate the likelihood that we need in the PMCMC sampler. In order to have a constant time complexity, one can use the Markovian properties of the latent states by imposing some transition density $q_{t}( x_{t} \\mid x_{t-k})$ and propagating particles forward at each time step t. Afterwards, these particles will be weighted with the weight function we introduced above. Particles that are very unlikely given the observed data will then be replaced by more realistic particles - this has the effect that variance of our likelihood estimate will not be ’too’ large. After we propagated a bunch of particles forward up to the final time point T, we can sample one trajectory of these particles to get $P(s^{\\star}_{1:T} \\mid \\theta^{\\star}, e_{1:T})$ for our PMCMC algorithm.\nIf you read through the paper mentioned above, you will discover the optimal importance/proposal distribution in terms of minimising the variance of the likelihood estimate for processes with Markov property is $q(s_t \\mid s_{t-1}, e_t) = p(s_t \\mid s_{t-1}, e_t)$. This is usually not availabe, but gives some insight about good candidates. A common and simple choice is the so-called Bootstrap filter, which takes $q(s_t \\mid s_{t-1}, e_t) = p(s_t \\mid s_{t-1})$ and simplifies the corresponding particle weights to to $p(e_t \\mid s_t)$. Both of these distributions are readily available in the HMM and HSMM case, so we jump straight into the coding section.\nCoding our very first particle filter The first thing that we need to define is the particle filter container itself. We will use the same style and structure as in our HMM post, and the advantage of the Bootstrap filter is that we can just plug in the model distributions from the HMM to define our PF. As a result, we define a field for the initial and transition distribution for our particles. The last field, …","date":1602806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602806400,"objectID":"40eda38632362de4172f0193540e55fa","permalink":"https://paschermayr.github.io/post/statespacemodels-3-inference-on-state-space-models-part-2/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/post/statespacemodels-3-inference-on-state-space-models-part-2/","section":"post","summary":"Particle Filtering in State Space Models","tags":["State Space Models","Particle MCMC","Hidden Markov Model","Particle Filter","Julia"],"title":"Bayesian Inference on State Space Models - Part 2","type":"post"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Hi there! In my previous posts, I introduced two discrete state space model (SSM) variants: the hidden Markov model and hidden semi-Markov model. However, in all code examples, model parameter were already given - what happens if we need to estimate them? This post is the first of a series of four blog entries, in which I will explain a general framework to perform parameter inference on SSMs and implement a basic example for demonstration. Ideally, I would make all three posts as applied as my previous articles, but I have to use some theory in the beginning to make things easier going forward.\nWhile SSMs are very flexible and can describe data with a complex structure, parameter estimation can be very challenging. Analytical forms of the corresponding likelihood functions are only available in special cases and, thus, standard parameter optimization routines might be unfeasible. Consequently, the major challenge in solving SSMs is the generally intractable likelihood function $p_{\\theta}(e_{1:t}) = \\int p_{\\theta}(e_{1:t}, s_{1:t}) d s_{1:t}$, which integrates over the (unknown) latent state trajectory. As previously mentioned, $E_t$ is the observed data and $S_t$ the corresponding latent state.\nSo what can we do? If both $E_t$ and $S_t$ follow a Normal distribution, one may analytically estimate the corresponding model parameter via the so called Kalman equations, but given these very specific assumptions, we will not concentrate on this special case going forward. If $S_{1:T}$ is discrete, then the most common point estimation technique is the EM-Algorithm. In this case, one can use common filtering techniques, explained in (Rabiner, 1989), to iteratively calculate state probabilities and update model parameter. Once the EM-Algorithm has reached some convergence criterion, one may estimate the most likely state trajectory given the estimated parameter. I will not go into much detail here because this procedure has been explained on many occasions and will instead refer to the literature above. However, both approaches do not work in many cases. The former technique only works with very specific model assumptions. The latter technique is not available in case $S_{1:T}$ is continuous. Moreover, even if the state sequence is discrete, summing out the state space might be computationally very challenging if the latent state structure is complex. In addition, one may not be able to write down the analytical forms of the updating equations for more complex state space models.\nAnother popular approach is to use Gibbs sampling, where one uses the previously mentioned filtering techniques to obtain a sample from the whole state trajectory $S_{1:T}$, and then sample model parameter conditional on this path. This technique suffers from the usually high autocorrelation within the model parameter vector and the state sequence. Moreover, ideally one would like to perform estimation jointly for the model parameter $\\theta$ and the latent state space $S_{1:T}$, as both have a high interdependence as well. This is not feasible for either method that I mentioned so far. For a more in-depth discussion, an excellent comparison of point estimation and Bayesian techniques is given by (Ryden, 2008).\nA general framework to perform inference on state space models Given the statements above, I will now focus on a general approach to perform joint estimation on the model parameter and state trajectory of state space models, independent of the variate form of the latent space and the distributional assumptions on the observed variables. This is, to the best of my knowledge, only possible in a Bayesian setting, where we target the full joint posterior $P( s_{1:T}, \\theta \\mid e_{1:T})$ by iterating over the following steps:\npropose $\\theta^{\\star} \\sim f(\\theta^{\\star} \\mid \\theta)$ propose $S^\\star_{1:T} \\sim P(s^{\\star}_{1:T} \\mid \\theta^{\\star}, e_{1:T})$. and then accept this pair $(\\theta^{\\star}, s^{\\star}_{1:T})$ with acceptance probability $$ \\begin{equation} \\begin{split} A_{PMCMC} \u0026amp;= \\frac{ P( s^{\\star}_{1:T} \\mid \\theta^{\\star}) }{ P(s_{1:T} \\mid \\theta ) } \\frac{ P(e_{1:T} \\mid s^{\\star}_{1:T}, \\theta^{\\star}) }{ P(e_{1:T} \\mid s_{1:T}, \\theta ) } \\frac{ P(s_{1:T} \\mid e_{1:T}, \\theta) }{ P(s^{\\star}_{1:T} \\mid e_{1:T}, \\theta^{\\star}) } \\frac{P(\\theta^{\\star})}{P(\\theta)} \\frac{q(\\theta \\mid \\theta^{\\star})}{q(\\theta^{\\star} \\mid \\theta)} \\\\\\\\ \u0026amp;= \\frac{P(e_{1:T} \\mid \\theta^{\\star})}{P(e_{1:T} \\mid \\theta)} \\frac{P(\\theta^{\\star})}{P(\\theta)} \\frac{q(\\theta \\mid \\theta^{\\star})}{q(\\theta^{\\star} \\mid \\theta)}. \\\\ \\end{split} \\end{equation} $$ Okay, but what does that even mean? In the first step, we propose a new parameter vector $\\theta^{\\star}$ from a MCMC proposal distribution. I will not go over the basics of MCMC, as this has been explained in many other articles, but we will implement an example in part 3 of this tutorial. Given this $\\theta^{\\star}$, we sample a new trajectory $s^\\star_{1:T}$ and jointly accept …","date":1601596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601596800,"objectID":"b874057441ac19da58703bfe6bfbd84a","permalink":"https://paschermayr.github.io/post/statespacemodels-3-inference-on-state-space-models-part-1/","publishdate":"2020-10-02T00:00:00Z","relpermalink":"/post/statespacemodels-3-inference-on-state-space-models-part-1/","section":"post","summary":"Bayesian Inference on State Space Models","tags":["State Space Models","Particle MCMC"],"title":"Bayesian Inference on State Space Models - Part 1","type":"post"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Hi there! In the last article, you got a first impression about state space models and, as an example, the basic hidden Markov model: We already talked about various advantages of state space models, but - depending on the features of the underlying data that you want to model - basic HMMs just might not be good enough. Here is why:\nA geometric duration distribution is a problem Let us focus on the unobserved process, $S_t$, for now. We are interested in the actual time spent in a particular state. Let us calculate the probability that we are currently in state $i$ and remain here for the next two time steps. For a discrete 2-state, homogenous Markov chain, using the chain rule and the Markov assumption of the basic model, we can write: $$ \\begin{equation} \\begin{split} P( S_{t+3} = j, S_{t+2} = i, S_{t+1} = i \\mid S_{t} = i ) \u0026amp;= P( S_{t+3} = j\\mid S_{t+2} = i) P(S_{t+2} = i, \\mid S_{t+1} = i) P( S_{t+1} = i \\mid S_{t} = i ) \\\\ \u0026amp;= (1 - \\tau_{ii}) * \\tau_{ii}^2 \\end{split} \\label{eq:HMM_geom1} \\end{equation} $$\nIn general, for $t+k$ steps: $$ \\begin{equation} \\begin{split} P( S_{t+k} = j, \\dots, S_{t+1} = i \\mid S_{t} = i ) \u0026amp;= (1 - \\tau_{ii}) * \\tau_{ii}^{k-1} \\\\ \u0026amp;= Geometric_{ \\tau_{ii} }, \\end{split} \\label{eq:HMM_geom2} \\end{equation} $$ where the geometric distribution has to be interpreted as the length of state duration up to and including the transition to the other state. Why is this a problem? The hidden states you model may switch more rapidly than you would like them to do. Even if you assign parameter very close to the boundaries of its support, the duration distribution will always implicitly be geometric. That makes it unsuitable if you want to model something that is supposed to stay in a particular state for a long time. As an example, let us say you want to model economic cycles of a developed country. You typically expect an expansion to last on average 5-10 years, but modelling such long durations is unfeasable with daily input data for an HMM. To circumvent this issue, one may use weekly or monthly data, but why give up data and essential information if alternatives are available?\nFrom HMMs to HSMMs As a solution, we can model these state duration probabilities explicitly. Such models are known as hidden semi-Markov models (HSMM), and they are a powerful generalization of the basic HMM. HSMMs have an additional latent variable, lets call it $D_t$ for duration that determines how long one may stay in any given state. $S_t$ will only have the Markov property while transitioning, otherwise it is determined by $D_t$. The tuple $\\{ S_t, D_t \\}$ forms a so-called semi-Markov chain. Let us visualize this: In an HSMM, transitions are allowed only at the end of each state, resulting in the following distributional forms:\n\\begin{equation} S_t \\mid s_{t-1}, d_{t-1} \\sim P( S_t \\mid s_{t-1}, d_{t-1} ) = \\begin{cases} \\delta( S_{t} = s_{t-1}) \u0026amp;\\text{ $d_{t-1} \u0026gt; 0$ }\\\\\\\\ \\mathcal{T}_{s_{t-1},.} \u0026amp;\\text{ $d_{t-1} = 0$ } \\end{cases} \\label{eq:EDHMM_transition} \\end{equation} \\begin{equation} D_t \\mid s_{t}, d_{t-1} \\sim P(D_t \\mid s_{t}, d_{t-1}) = \\begin{cases} \\delta( D_{t} = d_{t-1} - 1) \u0026amp;\\text{ $d_{t-1} \u0026gt; 0$ } \\\\\\\\ \\mathcal{D}_{s_{t}} \u0026amp;\\text{ $d_{t-1} = 0$ } \\end{cases} \\label{eq:EDHMM_duration} \\end{equation} \\begin{equation} E_t \\mid s_{t} \\sim \\mathcal{O}_{s_{t}} \\label{eq:EDHMM_observation} \\end{equation} where $\\delta(a,b)$ is the Kronecker product and equals $1$ if $a = b$ and $0$ otherwise.\nNote that, as we model the duration explicitly now, we have to slightly adjust the transition matrix that we used in the previous article. The diagonal elements of the transition matrix - the probability to remain in any given state in the next time step, which formally is depicted as $\\tau_{i,i} = P(s_{t+1} = i \\mid s_{t} = i)$ - are now set to 0. The rest of the row elements in the transition matrix still need to sum up to 1. If you have trouble understanding that, check out the code below.\nLet us code! To understand the code for sampling a single trajectory of said HSMM more clearly, keep reading:\nThe function input are the model distributions stated above.\nThe function output is a single trajectory of the observed and latent variables.\nBefore we start the for-loop over time, we need to define the initial state. If the latent states of the data are conceived as a subsequence of a long-running process, the probability of the initial state should be set to the stationary state probabilities of this unobserved Markov chain. This plays an important part in the estimation paradigm, but for now we simply choose any of the available states with equal probability. Don’t worry if this sounds difficult - we will come back to it in a later article.\nThe for-loop samples the new state given the old state, and then the observation given the new state, over time. The corresponding distributions are stated above.\nIn the HSMM case, we check if the duration in the previous time step reached 0. If true, we sample a new …","date":1600387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600387200,"objectID":"1c97a63f333aa014ad8ec931bf162aea","permalink":"https://paschermayr.github.io/post/statespacemodels-2-hsmm/","publishdate":"2020-09-18T00:00:00Z","relpermalink":"/post/statespacemodels-2-hsmm/","section":"post","summary":"Introduction to Hidden semi-Markov Models","tags":["State Space Models","Hidden semi-Markov Model","Julia"],"title":"State Space Models Everywhere! Round 1 - HSMM","type":"post"},{"authors":null,"categories":null,"content":"A blog series introducing HMMs and HSMMs, where a parameter estimation framework is built from scratch for such models, see here.\n","date":1599609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599609600,"objectID":"e7a69f4717e124636e8d938c8e31f8b9","permalink":"https://paschermayr.github.io/project/statespacemodels/","publishdate":"2020-09-09T00:00:00Z","relpermalink":"/project/statespacemodels/","section":"project","summary":"Blog series introducing HMMs and HSMMs","tags":["State Space Models","Parameter Estimation","Bayesian Statistics"],"title":"State Space Models Everywhere","type":"project"},{"authors":["Patrick Aschermayr"],"categories":["State Space Models"],"content":"Welcome! In my first series of posts, I will give a primer on state space models (SSM) that will lay a foundation in understanding upcoming posts about their variants, usefulness, methods to apply inference and forecasting possibilities. When talking about a state space model (SSM), people usually refer to a bivariate stochastic process $\\{ E_t, S_t \\}_{t = 1,2,\\ldots ,T }$, where $S_t$ is an unobserved Markov chain and $E_t$ is an observed sequence of random variables. This may sounds difficult now, so let us look at a graphical example of one of the most well known SSMs out there - the so called Hidden Markov Model (HMM): So, what are SSMs really? Cool! To sum up the idea above in words, there is some unobserved process $S_t$ guiding the underlying data $E_t$. The Greek letters in the square box are the corresponding model parameter, which we assume to be fixed for now, and their priors. For example, maybe you own some shares of a company? Then the periodic changes in your portfolio, $e_t$, will be influenced by the current state of the economy, $s_t$. Hence, you may model this relationship as an HMM. There are many different variants of the model stated above, which I will discuss in future posts. One may include some autoregressive structure for the observation sequence, or one may decide to model the state sequence as a higher order Markov chain or even as a semi-Markov chain. Depending on the underlying data you want to model, one may also want to combine several of these ideas.\nAnd why are they useful? It turns out that having an underlying, unobserved process guiding some observed variables is a phenomenon that comes up naturally in many different areas. While I used an example from finance, there are many areas in genetics, anomaly detection and speech and pattern recognition, among others, where this structure comes up naturally and SSM can be applied successfully. Moreover, these models\ncan handle structural breaks, shifts, or time-varying parameters of a model. Model parameter will adjust depending on the current state.\nallow you to model complex and nonlinear relationships.\nhandle missing and irregular spaced data easily.\ncan be used to do forecasting naturally due to their sequential setting.\nhave interpretable structure to perform inference.\nSo even if someone is only interested in the observed sequence, the addition of a latent variable offers much additional flexibility that might not be feasable otherwise. This comes at the price that SSMs are, in general, computationally hard to estimate. I will go further into this topic in a separate post.\nSampling our very first State Space Model For our first SMM, we will use observations that are normally distributed given the states. In this case, $S_t$ is a first order Markov chain, which can be depicted as a so called transition matrix $\\tau$ . Each row in this matrix has a Categorical distribution, and the parameters thus have to sum up to 1 and are bounded between 0 and 1. $$ \\begin{equation} \\begin{split} \u0026amp; e_t \\sim Normal(\\mu_{s_t}, \\sigma_{s_t} ) \\\\ \u0026amp; s_t \\sim Categorical( \\tau_{s_{t-1}}) \\ \\end{split} \\end{equation} $$ Let’s write down a function that can generate sample paths of the HMM from above. I will mainly use Julia in my blog posts, as this programming language is incredibly fast and readable, and has some amazing features to make the life of anyone doing scientific computational research much easier. Here are some notes to help understand the code to sample a single trajectory of said HMM:\nThe function input are the model distributions stated above.\nThe function output is a single trajectory of the observed and latent variables.\nBefore we start the for loop over time, we need to define the initial state. If the latent states of the data are conceived as a subsequence of a long-running process, the probability of the initial state should be set to the stationary state probabilities of this unobserved Markov chain. This plays an important part in the estimation paradigm, but for now we simply choose any of the available states with equal probability. Don’t worry if this sounds difficult for you - we will come back to it in a future post.\nThe for loop samples the new state given the old state, and then the observation given the new state, over time. The corresponding distributions are stated above.\nThat’s it! Let us have a look:\nusing Plots, Distributions function sampleHMM(evidence::Vector{\u0026lt;:Distribution}, transition::Vector{\u0026lt;:Distribution}, T::Int64) #Initialize states and observations state = zeros(Int64, T) observation = zeros(Float64, T) #Sample initial s from initial distribution state[1] = rand( 1:length(transition) ) #not further discussed here observation[1] = rand( evidence[ state[1] ] ) #Loop over Time Index for time in 2:T state[time] = rand( transition[ state[time-1] ] ) observation[time] = rand( evidence[ state[time] ] ) end return state, observation end sampleHMM (generic function with 1 method) To round out this post, …","date":1599350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599350400,"objectID":"4b8851d3c3cd0e808a81dc03001d20e5","permalink":"https://paschermayr.github.io/post/statespacemodels-1-a-primer-on-state-space-models/","publishdate":"2020-09-06T00:00:00Z","relpermalink":"/post/statespacemodels-1-a-primer-on-state-space-models/","section":"post","summary":"Introduction to State Space Models","tags":["State Space Models","Hidden Markov Model","Julia"],"title":"A Primer on State Space Models","type":"post"},{"authors":["Patrick Aschermayr"],"categories":["Academic","Teaching","Bayesian Statistics"],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"02e7cf52226d97ee0bd131068e2bb95d","permalink":"https://paschermayr.github.io/teaching/lse-2020-st308-bayesian-inference/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/teaching/lse-2020-st308-bayesian-inference/","section":"teaching","summary":"Graduate teaching assistant in my second year of PhD studies at the LSE.","tags":["Academic","Teaching","Bayesian Statistics"],"title":"LSE - ST308 - Bayesian Inference (2020)","type":"teaching"},{"authors":[],"categories":null,"content":"","date":1558357200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558357200,"objectID":"9c19c920e2b9a81836b02d4db970eb59","permalink":"https://paschermayr.github.io/talk/lse-2019-seds/","publishdate":"2019-05-20T13:00:00Z","relpermalink":"/talk/lse-2019-seds/","section":"talk","summary":"Research Poster Presentation about Particle MCMC Methods","tags":[],"title":"Social and Economic Data Science Summit - Research Poster Presentation","type":"talk"},{"authors":[],"categories":null,"content":"","date":1556715600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556715600,"objectID":"67127ef9e7679e92608934e148a3ba11","permalink":"https://paschermayr.github.io/talk/lse-2019-phd-research-update/","publishdate":"2019-05-01T13:00:00Z","relpermalink":"/talk/lse-2019-phd-research-update/","section":"talk","summary":"Bayesian Inference for hidden Semi-Markov Models","tags":[],"title":"Research Update Presentation","type":"talk"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://paschermayr.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Patrick Aschermayr"],"categories":["Academic","Teaching","Statistics"],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3667e5ff51180a4946e3e189175f10e2","permalink":"https://paschermayr.github.io/teaching/lse-2019-st107-quantitative-methods/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/teaching/lse-2019-st107-quantitative-methods/","section":"teaching","summary":"Graduate teaching assistant in my first year of PhD studies at the LSE.","tags":["Academic","Teaching","Statistics"],"title":"LSE - ST107 - Quantitative Methods (2019)","type":"teaching"}]